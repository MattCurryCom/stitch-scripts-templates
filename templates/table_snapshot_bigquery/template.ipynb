{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create a  table snapshot in BigQuery\n",
        "\n",
        "Selects all of the data from a given source table and appends it to a destination table with the current timestamp. This deals with schema changes by appending columns that did not previously exist to the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.cloud import bigquery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conn = stitch_context.connections['Default Warehouse']['client']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # DO ONLY ONCE\n",
        "# # create a new dataset for your daily snapshots\n",
        "\n",
        "# dataset_ref = conn.dataset('snapshots_dataset')\n",
        "\n",
        "# dataset = bigquery.Dataset(dataset_ref)\n",
        "# dataset.location = 'US'\n",
        "# conn.create_dataset(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # DO ONLY ONCE\n",
        "# # create a new table\n",
        "\n",
        "# table_ref = dataset_ref.table('shakespeare_daily')\n",
        "# table = bigquery.Table(table_ref)\n",
        "# table = conn.create_table(table)  # API request\n",
        "\n",
        "# assert table.table_id == 'shakespeare_daily'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get info on destination dataset\n",
        "dataset_ref = conn.dataset('snapshots_dataset')\n",
        "\n",
        "# Retrieves the destination table and checks the length of the schema\n",
        "table_id = 'shakespeare_daily'\n",
        "table_ref = dataset_ref.table(table_id)\n",
        "table = conn.get_table(table_ref)\n",
        "\n",
        "log.info(\"Table {} contains {} columns.\".format(table_id, len(table.schema)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# configure the query to append the results to a destination table,\n",
        "# allowing field addition\n",
        "\n",
        "try:\n",
        "    job_config = bigquery.QueryJobConfig()\n",
        "    job_config.schema_update_options = [\n",
        "        bigquery.SchemaUpdateOption.ALLOW_FIELD_ADDITION,\n",
        "    ]\n",
        "    job_config.destination = table_ref\n",
        "    job_config.write_disposition = bigquery.WriteDisposition.WRITE_APPEND\n",
        "except Exception as e:\n",
        "    log.error(e)\n",
        "\n",
        "query_job = conn.query(\n",
        "    \n",
        "#     select everything from your source dataset\n",
        "#     and add a created_at column with the current timestamp.\n",
        "#     current_datetime returns UTC timestamp\n",
        "    'SELECT *, CURRENT_DATETIME() as created_at from `bigquery-public-data.samples.shakespeare`;', \n",
        "    \n",
        "# Location must match that of the dataset(s) referenced in the query\n",
        "# and of the destination table.\n",
        "    location='US',\n",
        "    job_config=job_config\n",
        ")  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    query_job.result()  # Waits for the query to finish\n",
        "    print(\"Query job {} complete.\".format(query_job.job_id))\n",
        "    log.info(\"Query job {} complete.\".format(query_job.job_id))\n",
        "except Exception as e:\n",
        "    log.error(e)\n",
        "\n",
        "# check the updated length of the schema\n",
        "\n",
        "table = conn.get_table(table)\n",
        "\n",
        "log.info(\"Table {} now contains {} columns.\".format(table_id, len(table.schema)))\n",
        "\n",
        "# look at the new timestamps\n",
        "\n",
        "sql = \"\"\"\n",
        "    select distinct created_at\n",
        "    from snapshots_dataset.shakespeare_daily\n",
        "    limit 10\n",
        "\"\"\"\n",
        "\n",
        "conn.query(sql).to_dataframe()"
      ]
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 1
}
